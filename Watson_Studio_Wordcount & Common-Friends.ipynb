{"cells": [{"metadata": {"scrolled": true}, "cell_type": "code", "source": "sc.version\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191217160124-0000\nKERNEL_ID = 80c69eaa-cc55-4f09-ad1f-62086200cd76\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'2.3.3'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "PART-1:  \"WORDCOUNT\" EXAMPLE USING MAPREDUCE"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Fetch the text file for wordcount example\n!wget https://raw.githubusercontent.com/ibarabasi/wordcount/master/wordcount\n!cat wordcount", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "--2019-12-17 16:01:35--  https://raw.githubusercontent.com/ibarabasi/wordcount/master/wordcount\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 710 [text/plain]\nSaving to: 'wordcount'\n\n100%[======================================>] 710         --.-K/s   in 0s      \n\n2019-12-17 16:01:36 (32.0 MB/s) - 'wordcount' saved [710/710]\n\nBig data refers to the massive amount of data which cannot be stored, processed and analyzed using traditional ways.\nThe main elements of big data are:\nVolume - There is a massive amount of data generated every second.\nVelocity - The speed at which data is generated, collected and analyzed\nVariety - The different types of data: structured, semi-structured, unstructured\nValue - The ability to turn data into useful insights for your business\nVeracity - Trustworthiness in terms of quality and accuracy\nThe main challenges that big data faced and the solutions for each are listed below:\nSingle central storage\nSerial processing\nOne input\nOne Output\nOne Processor\nLack of ability to process unstructured data\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Simple example to read text file\nrdd0 = sc.textFile(\"wordcount\")\nrdd0.take(20)", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "['Big data refers to the massive amount of data which cannot be stored, processed and analyzed using traditional ways.',\n 'The main elements of big data are:',\n 'Volume - There is a massive amount of data generated every second.',\n 'Velocity - The speed at which data is generated, collected and analyzed',\n 'Variety - The different types of data: structured, semi-structured, unstructured',\n 'Value - The ability to turn data into useful insights for your business',\n 'Veracity - Trustworthiness in terms of quality and accuracy',\n 'The main challenges that big data faced and the solutions for each are listed below:',\n 'Single central storage',\n 'Serial processing',\n 'One input',\n 'One Output',\n 'One Processor',\n 'Lack of ability to process unstructured data']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "word_counts = rdd0.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: (a + b)).map(lambda x:(x[1],x[0]))\n\nword_counts.take(30)\n", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "[(1, 'refers'),\n (2, 'massive'),\n (2, 'amount'),\n (6, 'of'),\n (1, 'cannot'),\n (1, 'processed'),\n (1, 'using'),\n (1, 'traditional'),\n (5, 'The'),\n (1, 'are:'),\n (2, 'is'),\n (1, 'generated'),\n (1, 'second.'),\n (1, 'Velocity'),\n (1, 'speed'),\n (1, 'at'),\n (1, 'generated,'),\n (1, 'different'),\n (1, 'semi-structured,'),\n (1, 'Value'),\n (1, 'turn'),\n (1, 'into'),\n (1, 'useful'),\n (1, 'business'),\n (1, 'Veracity'),\n (1, 'in'),\n (1, 'quality'),\n (1, 'challenges'),\n (1, 'faced'),\n (1, 'are')]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "PART-2:  \"COMMON FRIENDS\" EXAMPLE USINg MAPREDUCE"}, {"metadata": {}, "cell_type": "code", "source": "# Load data from github\n!wget \"https://raw.githubusercontent.com/ibarabasi/wordcount/master/friends\"\nrdd = sc.textFile(\"friends\")\n!cat friends", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "--2019-12-17 16:02:10--  https://raw.githubusercontent.com/ibarabasi/wordcount/master/friends\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 193 [text/plain]\nSaving to: 'friends'\n\n100%[======================================>] 193         --.-K/s   in 0s      \n\n2019-12-17 16:02:10 (9.65 MB/s) - 'friends' saved [193/193]\n\nme Alice\nHenry me\nHenry Alice\nme Jane\nAlice John\nJane John\nJudy Alice\nme Mary\nMary Joyce\nJoyce Henry\nJudy me\nJudy Jane\nJohn Carol\nCarol me\nMary Henry\nLouise Ronald\nRonald Thomas\nWilliam Thomas\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!cat wordcount/friends\n# Build the first pair RDD\nrdd0 = rdd.map(lambda x: x.split())\nrdd0.take(20)", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "cat: wordcount/friends: Not a directory\r\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "[['me', 'Alice'],\n ['Henry', 'me'],\n ['Henry', 'Alice'],\n ['me', 'Jane'],\n ['Alice', 'John'],\n ['Jane', 'John'],\n ['Judy', 'Alice'],\n ['me', 'Mary'],\n ['Mary', 'Joyce'],\n ['Joyce', 'Henry'],\n ['Judy', 'me'],\n ['Judy', 'Jane'],\n ['John', 'Carol'],\n ['Carol', 'me'],\n ['Mary', 'Henry'],\n ['Louise', 'Ronald'],\n ['Ronald', 'Thomas'],\n ['William', 'Thomas']]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "rdd1=rdd0.union(rdd.map(lambda x: x.split()[::-1]))\n# Bring my friend list to local\nlst = rdd1.filter(lambda x: x[0] == 'me').map(lambda x: x[1]).collect()\n# Build the second pair RDD\nrdd2 = rdd1.filter(lambda x: x[0] in lst).map(lambda x: x[1]). \\\n    filter(lambda x: x != 'me' and x not in lst). \\\n    map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b). \\\n    map(lambda x: (x[1], x[0])).sortByKey(ascending = False)\n# Bring the result to local since the sample is small\nfor x, y in rdd2.collect():\n    print (\"The stranger {} has {} common friends with me\".format(y, x))\n", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "The stranger John has 3 common friends with me\nThe stranger Joyce has 2 common friends with me\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python36", "display_name": "Python 3.6 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.8", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}